{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import tensorflow as tf\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\supra\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murtozalikhon\\brain-tumor-multimodal-image-ct-and-mri\\versions\\1\n",
      "\n",
      "Exploring the dataset structure...\n",
      "\n",
      "Folder: Dataset\n",
      "  Subfolder: Brain Tumor CT scan Images\n",
      "    Number of images: 3\n",
      "  Subfolder: Brain Tumor MRI images\n",
      "    Number of images: 3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"murtozalikhon/brain-tumor-multimodal-image-ct-and-mri\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Inspect the dataset structure\n",
    "print(\"\\nExploring the dataset structure...\\n\")\n",
    "for folder in os.listdir(path):\n",
    "    print(f\"Folder: {folder}\")\n",
    "    subfolder_path = os.path.join(path, folder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for subfolder in os.listdir(subfolder_path):\n",
    "            print(f\"  Subfolder: {subfolder}\")\n",
    "            image_files = os.listdir(os.path.join(subfolder_path, subfolder))\n",
    "            print(f\"    Number of images: {len(image_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r' C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murtozalikhon\\brain-tumor-multimodal-image-ct-and-mri\\versions\\1\\Dataset'\n",
    "ct_path = os.path.join(path, \"Brain Tumor CT scan Images\")\n",
    "mri_path = os.path.join(path, \"Brain Tumor MRI images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding MRI Healthy images...\n",
      "Added 1997 MRI Healthy images.\n",
      "Adding MRI Tumor images...\n",
      "Total images after MRI Tumor: 4981\n",
      "Adding CT Healthy images...\n",
      "Total images after CT Healthy: 6697\n",
      "Adding CT Tumor images...\n",
      "Total images after CT Tumor: 8854\n",
      "\n",
      "Sample DataFrame:\n",
      "                                                path  label modality\n",
      "0  C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murto...      0      MRI\n",
      "1  C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murto...      0      MRI\n",
      "2  C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murto...      0      MRI\n",
      "3  C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murto...      0      MRI\n",
      "4  C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murto...      0      MRI\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "1    5141\n",
      "0    3713\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Modality Distribution:\n",
      "modality\n",
      "MRI    4981\n",
      "CT     3873\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define dataset paths\n",
    "mri_healthy_path = r\"C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murtozalikhon\\brain-tumor-multimodal-image-ct-and-mri\\versions\\1\\Dataset\\Brain Tumor MRI images\\Healthy\"\n",
    "mri_tumor_path = r\"C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murtozalikhon\\brain-tumor-multimodal-image-ct-and-mri\\versions\\1\\Dataset\\Brain Tumor MRI images\\Tumor\"\n",
    "ct_healthy_path = r\"C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murtozalikhon\\brain-tumor-multimodal-image-ct-and-mri\\versions\\1\\Dataset\\Brain Tumor CT scan Images\\Healthy\"\n",
    "ct_tumor_path = r\"C:\\Users\\supra\\.cache\\kagglehub\\datasets\\murtozalikhon\\brain-tumor-multimodal-image-ct-and-mri\\versions\\1\\Dataset\\Brain Tumor CT scan Images\\Tumor\"\n",
    "\n",
    "# Initialize data list\n",
    "data = []\n",
    "\n",
    "# Add MRI Healthy\n",
    "print(\"Adding MRI Healthy images...\")\n",
    "for img_path in glob.glob(os.path.join(mri_healthy_path, \"*.jpg\")):\n",
    "    data.append((img_path, 0, \"MRI\"))\n",
    "print(f\"Added {len(data)} MRI Healthy images.\")\n",
    "\n",
    "# Add MRI Tumor\n",
    "print(\"Adding MRI Tumor images...\")\n",
    "for img_path in glob.glob(os.path.join(mri_tumor_path, \"*.jpg\")):\n",
    "    data.append((img_path, 1, \"MRI\"))\n",
    "print(f\"Total images after MRI Tumor: {len(data)}\")\n",
    "\n",
    "# Add CT Healthy\n",
    "print(\"Adding CT Healthy images...\")\n",
    "for img_path in glob.glob(os.path.join(ct_healthy_path, \"*.jpg\")):\n",
    "    data.append((img_path, 0, \"CT\"))\n",
    "print(f\"Total images after CT Healthy: {len(data)}\")\n",
    "\n",
    "# Add CT Tumor\n",
    "print(\"Adding CT Tumor images...\")\n",
    "for img_path in glob.glob(os.path.join(ct_tumor_path, \"*.jpg\")):\n",
    "    data.append((img_path, 1, \"CT\"))\n",
    "print(f\"Total images after CT Tumor: {len(data)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"path\", \"label\", \"modality\"])\n",
    "print(\"\\nSample DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Check modality distribution\n",
    "print(\"\\nModality Distribution:\")\n",
    "print(df['modality'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI - Training samples: 3984, Validation samples: 997\n",
      "CT - Training samples: 3098, Validation samples: 775\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data(df, img_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Load the image\n",
    "        img = cv2.imread(row['path'], cv2.IMREAD_COLOR)\n",
    "        if img is None:  # Handle failed image loading\n",
    "            print(f\"Warning: Failed to load image at {row['path']}\")\n",
    "            continue\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        images.append(img)\n",
    "        labels.append(row['label'])\n",
    "    if len(images) == 0:  # Handle case where no images are loaded\n",
    "        raise ValueError(\"No images were loaded. Please check your dataset paths and formats.\")\n",
    "    images = np.array(images) / 255.0  # Normalize\n",
    "    labels = to_categorical(labels, num_classes=2)  # One-hot encode\n",
    "    return images, labels\n",
    "\n",
    "# Preprocess data for MRI and CT\n",
    "img_size = 224  # MobileNet input size\n",
    "\n",
    "# Process MRI data\n",
    "try:\n",
    "    X_mri, y_mri = preprocess_data(df[df['modality'] == 'MRI'], img_size)\n",
    "except ValueError as e:\n",
    "    print(f\"Error processing MRI data: {e}\")\n",
    "    X_mri, y_mri = np.array([]), np.array([])\n",
    "\n",
    "# Process CT data\n",
    "try:\n",
    "    X_ct, y_ct = preprocess_data(df[df['modality'] == 'CT'], img_size)\n",
    "except ValueError as e:\n",
    "    print(f\"Error processing CT data: {e}\")\n",
    "    X_ct, y_ct = np.array([]), np.array([])\n",
    "\n",
    "# Check if datasets are not empty before splitting\n",
    "if X_mri.size > 0 and y_mri.size > 0:\n",
    "    X_train_mri, X_val_mri, y_train_mri, y_val_mri = train_test_split(\n",
    "        X_mri, y_mri, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"MRI - Training samples: {len(X_train_mri)}, Validation samples: {len(X_val_mri)}\")\n",
    "else:\n",
    "    print(\"MRI data is empty. Skipping training/validation split for MRI.\")\n",
    "\n",
    "if X_ct.size > 0 and y_ct.size > 0:\n",
    "    X_train_ct, X_val_ct, y_train_ct, y_val_ct = train_test_split(\n",
    "        X_ct, y_ct, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"CT - Training samples: {len(X_train_ct)}, Validation samples: {len(X_val_ct)}\")\n",
    "else:\n",
    "    print(\"CT data is empty. Skipping training/validation split for CT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17225924/17225924 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "def build_mobilenet_model(input_shape):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze base model layers for transfer learning\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (img_size, img_size, 3)\n",
    "\n",
    "# Build models for MRI and CT\n",
    "mri_model = build_mobilenet_model(input_shape)\n",
    "ct_model = build_mobilenet_model(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MRI Model...\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 5s 40ms/step - loss: 0.0916 - accuracy: 0.9671 - val_loss: 0.0677 - val_accuracy: 0.9749\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0980 - accuracy: 0.9639 - val_loss: 0.0668 - val_accuracy: 0.9779\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0843 - accuracy: 0.9701 - val_loss: 0.0720 - val_accuracy: 0.9719\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0884 - accuracy: 0.9671 - val_loss: 0.0706 - val_accuracy: 0.9749\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0761 - accuracy: 0.9741 - val_loss: 0.0645 - val_accuracy: 0.9789\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0775 - accuracy: 0.9716 - val_loss: 0.0635 - val_accuracy: 0.9779\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0788 - accuracy: 0.9684 - val_loss: 0.0656 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0859 - accuracy: 0.9689 - val_loss: 0.0673 - val_accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0843 - accuracy: 0.9691 - val_loss: 0.0679 - val_accuracy: 0.9789\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.0929 - accuracy: 0.9669 - val_loss: 0.0663 - val_accuracy: 0.9779\n",
      "Training CT Model...\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 4s 45ms/step - loss: 0.0868 - accuracy: 0.9687 - val_loss: 0.0670 - val_accuracy: 0.9806\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0974 - accuracy: 0.9645 - val_loss: 0.0663 - val_accuracy: 0.9806\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.1065 - accuracy: 0.9613 - val_loss: 0.0681 - val_accuracy: 0.9781\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.1020 - accuracy: 0.9651 - val_loss: 0.0661 - val_accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0929 - accuracy: 0.9690 - val_loss: 0.0616 - val_accuracy: 0.9819\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0887 - accuracy: 0.9658 - val_loss: 0.0614 - val_accuracy: 0.9781\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0955 - accuracy: 0.9664 - val_loss: 0.0626 - val_accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0850 - accuracy: 0.9693 - val_loss: 0.0623 - val_accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0948 - accuracy: 0.9616 - val_loss: 0.0608 - val_accuracy: 0.9794\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.0941 - accuracy: 0.9635 - val_loss: 0.0636 - val_accuracy: 0.9806\n"
     ]
    }
   ],
   "source": [
    "# Train MRI model\n",
    "print(\"Training MRI Model...\")\n",
    "history_mri = mri_model.fit(\n",
    "    X_train_mri, y_train_mri,\n",
    "    validation_data=(X_val_mri, y_val_mri),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Train CT model\n",
    "print(\"Training CT Model...\")\n",
    "history_ct = ct_model.fit(\n",
    "    X_train_ct, y_train_ct,\n",
    "    validation_data=(X_val_ct, y_val_ct),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_model.save('mri_model_mobilenet.h5')\n",
    "ct_model.save('ct_model_mobilenet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def predict_tumor_single(mri_model_path, ct_model_path, img_path, img_size=224):\n",
    "    \n",
    "    # Load the models\n",
    "    mri_model = load_model(mri_model_path)\n",
    "    ct_model = load_model(ct_model_path)\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read the image at {img_path}\")\n",
    "    \n",
    "    img = cv2.resize(img, (img_size, img_size)) / 255.0  # Resize and normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Predict using both models\n",
    "    mri_pred = mri_model.predict(img)[0][1]  # Tumor probability from MRI model\n",
    "    ct_pred = ct_model.predict(img)[0][1]  # Tumor probability from CT model\n",
    "    \n",
    "    # Combine predictions (average probabilities)\n",
    "    combined_pred = (mri_pred + ct_pred) / 2\n",
    "    \n",
    "    # Return True if tumor is detected, False otherwise\n",
    "    return combined_pred > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CFFC8E8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CFFC6100D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "Image: C:\\machine learning]\\brain tumor\\ct_healthy (20).png -> Tumor Detected: False\n"
     ]
    }
   ],
   "source": [
    "# Paths to the trained models\n",
    "mri_model_path = \"mri_model_mobilenet.h5\"\n",
    "ct_model_path = \"ct_model_mobilenet.h5\"\n",
    "\n",
    "# Path to the input image\n",
    "input_image = r\"C:\\machine learning]\\brain tumor\\ct_healthy (20).png\"\n",
    "\n",
    "# Predict\n",
    "try:\n",
    "    tumor_detected = predict_tumor_single(mri_model_path, ct_model_path, input_image)\n",
    "    print(f\"Image: {input_image} -> Tumor Detected: {tumor_detected}\")\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
